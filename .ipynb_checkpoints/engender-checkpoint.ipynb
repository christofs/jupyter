{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# engender - Das Vokabular weiblicher und männlicher Autoren englischer Romane des 19. Jahrhunderts im Vergleich\n",
    "\n",
    "Dieses Jupyter Notebook erläutert einige Aspekte des Vergleichs von (Sub-)Korpora am Beispiel einer Sammlung von Romanen, die von weiblichen und männlichen englischen Autoren des 19. Jahrhunderts geschrieben wurden.\n",
    "\n",
    "Das Notebook ist live unter http://mybinder.org/repo/christofs/jupyter und wurde im Juni 2016 von Christof Schöch erstellt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Das Thema dieser Lerneinheit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hintergrund zu dieser Übung ist der Vortrag \"Spitzer über Racine, revisited\". Dort wurde unter anderem die Häufigkeit von lexikalischen Mustern in den Tragödien Racines und in Tragödien zeitgenössischer Autoren verglichen. \n",
    "\n",
    "Ganz ähnlich werden hier nun die Häufigkeiten von Lemmata in den Romanen weiblicher und männlicher englischer AutorInnen des 19. Jahrhunderts verglichen. \n",
    "\n",
    "Die verwendete Textsammlung besteht aus 70 Romanen, von denen 35 von Autorinnen und 35 von Autoren verfasst wurden. Einige besonders lange Romane sind in mehrere Teile aufgeteilt worden, sodass insgesamt 120 Dokumente vorhanden sind. Die Textsammlung umfasst etwa 16.7 Millionen Tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ziele der Lerneinheit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Erstens: An einem konkreten Beispiel selbst zu prüfen, ob Männer und Frauen sich in ihrem Sprachgebrauch unterscheiden. Aber Vorsicht! Von dem Beispiel der englischen Romane des 19. Jahrhunderts lässt sich nicht auf die heutige Zeit schließen!\n",
    "* Zweitens: Ein Verständnis dafür zu entwickeln, dass die Häufigkeiten von Wortformen oder Lemmata in den verschiedenen Texten einer Textsammlung als Verteilung verstanden werden kann.  \n",
    "* Drittens: Zu verstehen, welche Möglichkeiten dies eröffnet: Solche Verteilungen können visualisiert werden, ihre zentralen Eigenschaften können bestimmt werden, und sie können mit geeigneten statistischen Tests verglichen werden.\n",
    "* Viertens: Es geht darum, an konkreten Beispielen den Zusammenhang zwischen der Bedeutung eines Wortes, der Visualisierung seiner Verteilung und den statistischen Kennwerten zu erfahren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Einige Hinweise zu den Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das vorliegende Dokument ist ein Jupyter Notebook für Python. Es besteht aus Textfeldern und Code-Feldern. Die Code-Felder sind interaktiv, d.h. der enthaltene Code kann ausgeführt werden. Es können auch Veränderungen vorgenommen werden, die sich dann auf das Ergebnis auswirken. \n",
    "\n",
    "* Eine Code-Zelle wird ausgeführt, indem man Strg+Enter drückt. \n",
    "* Die Code-Zellen bauen aufeinander auf, d.h. sie müssen nacheinander ausgeführt werden.\n",
    "* Um alle Code-Zellen ab einer bestimmten Stelle nacheinander auszuführen, klickt man im Menü auf \"Cell\", dann auf \"Run All Below\". \n",
    "* Um noch einmal neu zu beginnen und alle Änderungen zu löschen, klickt man im Menü auf \"Cell\", dann ganz unten auf \"All Output\" und dann auf \"Clear\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor es richtig losgehen kann, müssen die folgenden Erweiterungen für Python importiert (d.h., aktiviert) werden. Versuchen Sie gleich einmal, die erste Code-Zelle auszuführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start: Laden der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die für die folgenden Funktionen notwendigen Daten liegen bereits in einer Tabelle vor. Die Tabelle enthält für verschiedene Suchbegriffe die relativen Häufigkeiten in allen Texten der Sammlung.\n",
    "\n",
    "Jede Zeile der Tabelle steht für einen Suchbegriff. Jede Spalte der Tabelle steht für einen Roman, der über ein Kürzel identifiziert ist. In jeder Zelle steht die relative Häufigkeit eines Suchbegriffs für einen Roman. (Die relative Häufigkeit ist hier definiert als die absolute Häufigkeit geteilt durch die Textlänge mal 1000. Die beantwortet also die Frage: Wie oft kommt das Wort pro 1000 Tokens im Text vor?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daten laden\n",
    "\n",
    "Der folgende Code lädt die Datentabelle und zeigt einen kleinen Ausschnitt daraus an. \n",
    "\n",
    "Tatsächlich ist die Tabelle natürlich viel größer. Sie hat 120 Zeilen, eine für jeden Roman, und je eine Spalte pro Suchwort.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AlleDaten = \"AlleDaten.csv\"\n",
    "with open(AlleDaten, \"r\") as infile: \n",
    "    AlleDaten = pd.DataFrame.from_csv(infile, sep=\",\")\n",
    "    print(AlleDaten.iloc[0:5,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genauerer Blick in die Daten\n",
    "\n",
    "Um genau die Daten auswählen zu können, die uns interessieren, müssen wir wissen, für welche Suchbegriffe Daten vorliegen. Der folgende Code ruft die Liste der enthaltenen Suchbegriffe ab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Suchbegriffe = AlleDaten.columns.values[1:]\n",
    "print(Suchbegriffe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufteilung der Daten in zwei Gruppen\n",
    "\n",
    "Wie Sie oben schon gesehen haben liegt in der Datentabelle für jeden Roman außer dem Kürzel auch die Information vor, ob er von einem Mann oder einer Frau geschrieben wurde. Diese Information können wir nutzen, um die Daten in zwei Teile aufzuteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GrpDaten = AlleDaten.groupby(\"gender\")\n",
    "DatenW = GrpDaten.get_group(\"w\")\n",
    "DatenM = GrpDaten.get_group(\"m\")\n",
    "print(\"\\nDatenW\\n\", DatenW.iloc[0:5,0:5])\n",
    "print(\"\\nDatenM\\n\", DatenM.iloc[0:5,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Auswählen eine Suchanfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf der Grundlage der vorliegenden Daten können wir nun die relativen Häufigkeiten für einen Begriff und für die weiblichen bzw. die männlichen Autoren aus der Tabelle extrahieren.\n",
    "\n",
    "Im folgenden Code-Feld muss ein Suchbegriff eingetragen werden. Bilden Sie zu einem der Suchbegriffe eine Hypothese und notieren Sie diese in der folgenden Code-Zelle. Dann machen Sie mit der Übung weiter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tragen Sie hier den Suchbegriff ein, zu dem Sie eine Hypothese haben.\n",
    "Suchbegriff = \"boy\" \n",
    "\n",
    "# Schreiben Sie hier in knapper Form Ihre Hypothese auf. \n",
    "Hypothese = \"\"\n",
    "\n",
    "print(\"\\nMeine Hypothese zu \"+Suchbegriff+\": \"+Hypothese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt nutzen wir die beiden Datentabellen und den Suchbegriff, um die entsprechenden Werte zu extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WerteW = DatenW.loc[:,Suchbegriff]\n",
    "WerteM = DatenM.loc[:,Suchbegriff]\n",
    "print(\"\\nWerteW\\n\", sorted(list(WerteW)))\n",
    "print(\"\\nWerteM\\n\", sorted(list(WerteM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisierung als Verteilungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obigen Listen der Häufigkeiten sind, vorsichtig ausgedrückt, etwas unübersichtlich. Bestenfalls kann man, wenn man die Listen sortiert, die ihre Spannbreite der Werte ablesen.\n",
    "\n",
    "Zunächst visualisieren wir daher die beiden Verteilungen gemeinsam, um einen ersten Eindruck ihres Verhältnisses zueinander zu bekommen. Hierfür bieten sich sowohl Boxplots als auch Histogramme an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.boxplot([WerteW, WerteM], vert=False, patch_artist=True)\n",
    "plt.title(\"Boxplot für: \"+str(Suchbegriff))\n",
    "plt.xlabel(\"Häufigkeiten pro 1000 Tokens\")\n",
    "plt.yticks([1, 2], ['W', 'M'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Histogramm mit Dichteschätzung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(WerteM, kde=True, bins=16, label=\"M\").set(xlim=0)\n",
    "sns.distplot(WerteW, kde=True, bins=16, label=\"W\").set(xlim=0)\n",
    "plt.title(\"Histogramm für: \"+str(Suchbegriff))\n",
    "plt.xlabel(\"Häufigkeiten pro 1000 Tokens\")\n",
    "plt.ylabel(\"Anteil der Romane\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistische Eigenschaften der Verteilungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verteilungen kann man durch bestimmte Kennwerte beschreiben. Für sehr viele Verteilungen sind der Mittelwert, der Median und die Standardabweichung wichtige Kennwerte. \n",
    "\n",
    "Das ist auch für die hier vorliegenden Verteilungen nützlich. Allerdings sind sie durch diese Kennwerte nicht vollständig beschrieben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Mittelwerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MittelW = np.mean(WerteW)\n",
    "MittelM = np.mean(WerteM)\n",
    "print(\"\\nMittelwert W:\", MittelW, \"\\nMittelwert M:\", MittelM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mediane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MedianW = np.median(WerteW)\n",
    "MedianM = np.median(WerteM)\n",
    "print(\"\\nMedian W:\", MedianW)\n",
    "print(\"Median M:\", MedianM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "StandardabweichungW = np.std(WerteW)\n",
    "StandardabweichungM = np.std(WerteM)\n",
    "print(\"\\nStandardabweichung W:\", StandardabweichungW)\n",
    "print(\"Standardabweichung M:\", StandardabweichungM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistische Tests für den Unterschied der Verteilungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Vorüberlegungen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die im letzten Abschnitt ermittelten Werte unterscheiden sich, aber wie stark? Um dies zu entscheiden, können wir statistische Tests anwenden. Damit prüfen wir, ob sich die Verteilungen signifikant unterscheiden oder nicht. \n",
    "\n",
    "Genauer gesagt: Mit solchen Tests kann man die Null-Hypothese prüfen, dass zwei Verteilungen sich nicht signifikant unterscheiden. Das bedeutet, dass die beiden Verteilungen ebensogut zwei zufällige Samples aus der selben Verteilung sein könnten. In unserem Kontext entspricht die Null-Hypothese dem Befund, dass die Unterscheidung zwischen männlichen und weiblichen Autoren offenbar nicht wesentlich für die Häufigkeiten des Suchbegriffs ist. \n",
    "\n",
    "Welcher Test ist geeignet? Das ist fast die wichtigste Frage und ein Thema für sich. In unserem Fall gehen wir von folgenden Voraussetzungen aus: Wir wissen, dass die Daten unterschiedliche Mittelwerte und Varianzen haben. Und wir vermuten, dass die Daten nicht normalverteilt sind. In einem solchen Fall ist der Wilcoxon rank-sum Test ein angemessener Test. \n",
    "\n",
    "Der Wilcoxon-Test ermittelt u.a. einen p-Wert. Dieser gibt an, wie groß die Wahrscheinlichkeit ist, dass die beiden getesteten Verteilungen eigentlich der gleichen Verteilung entsprechen. Je kleiner der p-Wert, desto sicherer können wir sein, dass wir einen signifikanten Unterschied in der Häufigkeit eines Wortes bei männlichen und weiblichen Romanautoren gefunden haben. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Der Wilcoxon Rank-Sum Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokumentation: http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.wilcoxon.html\n",
    "\n",
    "Siehe auch: https://de.wikipedia.org/wiki/Wilcoxon-Vorzeichen-Rang-Test\n",
    "\n",
    "**Merke**: Nur wenn der Grenzwert von **p = 0,05** unterschritten wird, können wir die Null-Hypothese ablehnen und davon ausgehen, dass der beobachtete Unterschied signifikant ist. (Aber Vorsicht: dieser Grenzwert ist arbiträr.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Wilcoxon = stats.wilcoxon(WerteW, WerteM)\n",
    "print(\"\\nWilcoxon p-Wert für\", str(Suchbegriff),\":\", Wilcoxon[1])\n",
    "if Wilcoxon[1] < 0.05: \n",
    "    print(\"\\nDieser Wert bedeutet, dass der Unterschied SIGNIFIKANT ist.\")\n",
    "else: \n",
    "    print(\"\\nDieser Wert bedeutet, dass der Unterschied NICHT signifikant ist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entspricht das Ergebnis Ihren Erwartungen bzw. Ihrer oben formulierten Hypothese? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notizen\n",
    "Das folgende Textfeld können Sie nutzen, um sich Notizen zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mit Doppelklick aktivieren, mit Strg+Enter deaktivieren]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
